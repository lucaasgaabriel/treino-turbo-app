const axios = require('axios');

async function getGPT(prompt) {
    const apiKey = '';
    const url = 'https://api.openai.com/v1/chat/completions';

    try {
        const response = await axios.post(url, {
            model: 'gpt-3.5-turbo',
            messages: [{role: "user", content: prompt}],
            max_tokens: 150,
            temperature: 0.7,
        }, {
            headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${apiKey}`
            }
        });

        return response.data.choices[0].message.content.trim();
    } catch (error) {
        console.error('Erro ao chamar a API do OpenAI:', error.message);
        if (error.response) {
            console.error('Status Code:', error.response.status);
            console.error('Response Data:', error.response.data);
        }
        throw error;
    }
}

// Exemplo de uso
const prompt = 'Me informe 3 exercícios de perna em apenas 3 tópicos, irei consumir esses 3 treinos em um app'
getGPT(prompt).then(response => {
    console.log('Resposta do ChatGPT:', response);
}).catch(error => {
    console.error('Erro:', error.message);
});

const simulatedResponse = {
    id: "chatcmpl-6lEl5n9LK5cB5a5pXYZQ7AFHD7Vfz",
    object: "chat.completion",
    created: 1677649425,
    model: "gpt-3.5-turbo",
    choices: [
      {
        index: 0,
        message: {
          role: "assistant",
          content: "Here is the response text generated by the model."
        },
        finish_reason: "stop"
      }
    ],
    usage: {
      prompt_tokens: 10,
      completion_tokens: 20,
      total_tokens: 30
    }
  };
  
//   const res = {
//     id: "chatcmpl-6lEl5n9LK5cB5a5pXYZQ7AFHD7Vfz",
//     object: "chat.completion",
//     created: 1677649425,
//     model: "gpt-3.5-turbo",
//     choices: [
//       {
//         index: 0,
//         message: {
//           role: "assistant",
//           content: "Here is the response text generated by the model."
//         },
//         finish_reason: "stop"
//       }
//     ],
//     usage: {
//       prompt_tokens: 10,
//       completion_tokens: 20,
//       total_tokens: 30
//     }
//   }
  
